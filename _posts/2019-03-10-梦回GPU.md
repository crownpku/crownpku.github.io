---
layout: post
comments: true
title: 梦回GPU
published: true
---



2014年的时候我在香港一个研究机构，自己手头的一个项目是搭建三维扫描系统。原理简单讲就是用投影仪投射结构条纹到目标物体上，再用相机捕获在物体表面扭曲之后的条纹图像，然后反算出物体的三维点云。原型系统搭起来，算法在笔记本就能跑通，随便拿出手边的东西扫一扫，效果还是很有趣：

![](/images/201903/3.png)

客户是寻找芯片缺陷检测的方案；生产线上一条条芯片跑过去，对检测速度要求很高。所有能CPU并行的部分都并行了（其实就是对所有for loop用了openMP）速度还是不理想，于是想到要用GPU加速。

那个年代还没有tensorflow之类的东东，试过OpenCL试过C++ AMP，最后把公司重金买来却还没有用起来的GPU（当时还是K5000）放在台面，狠下心开始徒手写CUDA...

![](/images/201903/1.jpg)

终于快要交工的时候，挑选了大机箱、高性能主板、高功率电源，给老板搭好了4个GPU的服务器，还没怎么来得及用，我就决定离职直接去了一家造电脑的公司。


团队刚建立，一开始的主要工作是从总部运二手服务器回来。

![](/images/201903/5.jpg)

再之后做得最多的事情是开箱...

![](/images/201903/4.jpg)


幸福来得太突然。我独自坐在办公室里。夜已深，窗外的海面上只有邮轮的点点星光。脚下崭新的GPU服务器盖子还没扣上，机箱风扇呼呼作响，GeForce的信仰绿光照亮了我的下巴。我微微露出一丝笑意。

![](/images/201903/3.jpg)

我的Github大部分都是那段时间留下的遗产。写爬虫遇到验证码直接训练卷积网络怼；车牌识别用imageNet一堆模型随便试过去；拼音输入法用上seq2seq；文本生成把毛选全卷往里灌；实体识别和中文分词这种序列模型任性抛开BiLSTM去玩IDCNN，关系提取这种分类模型完全不理CNN去跑BiGRU，etc. etc...

然后天真躁动的我又去了一家金融公司做数据科学。一觉回到解放前。

我不是没有挣扎过。公司的计算环境连个pip都被墙。Google Colab和Kaggle Kernel都试过了，200多MB的内存是逗我么？AWS的GPU云服务、Google的TPU服务、Nvidia的新卡价格都让我真切意识到，**贫穷让我只剩下了想象力**。

而偏偏这个时候，NLP像当年CV一样翻天覆地地发展着。看着BERT、GPT-2这些东西，我只能默默地咽着口水，然后继续跑我的tf-idf...

于是我做了一个梦，梦见我跑通了GPT-10，解决了人类语言的终极奥秘。信仰绿光又一次照亮了我的下巴，~~泪~~口水沾湿了我的枕头。


