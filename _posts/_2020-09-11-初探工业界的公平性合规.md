---
layout: post
comments: true
title: 初探工业界的公平性合规
published: true
---

你在铁轨上散步，一辆火车轰隆隆驶来，前面有玩耍的孩子；如果你无动于衷，火车会撞到前面十几个个孩子，如果你扳动身边的扳手，火车会换轨撞到另一侧的三四个孩子。你会怎么做？

这是哈佛大学 [Justice](https://online-learning.harvard.edu/course/justice?delta=1) 课程第一节课上教授抛给学生的问题。

我们已经聊过几次从机器学习模型角度出发的公平正义性的问题，如：

* [Algorithms Auditing：你的代码公平正义吗？](http://www.crownpku.com/2018/11/14/Algorithms-Auditing-%E4%BD%A0%E7%9A%84%E4%BB%A3%E7%A0%81%E5%85%AC%E5%B9%B3%E6%AD%A3%E4%B9%89%E5%90%97.html)
* [机器学习模型的公平性评测](http://www.crownpku.com/2020/08/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7%E8%AF%84%E6%B5%8B.html)
* [GPT-3 的算法偏见](http://www.crownpku.com/2020/09/03/%E4%B8%8EGPT-3%E8%81%8A%E5%A4%A9%E6%90%9E%E5%AE%9Achatbot%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE.html)

工业界乃至哲学界对于公平性的讨论早在人工智能出现前很久就已经存在。从机器学习算法角度出发的模型公平性方案距离真正解决工业界的合规要求还有多远？我们暂时技术这顶帽子，从工业界的角度针对公平性合规这件事窥豹一斑。

本文开头提到的例子并没有正确答案，每个人有自己的理解和决定，也反映出公平和正义灰色的一面。实际中工业界关于法规关于公平性的定义也并没有统一的标准。下图是澳大利亚不同州对各种特定因素的反歧视法律规定：

![](/images/202009/2.png)

我们看到单单是同一个国家中的不同州，对一些特定因素（敏感特征）上的法规已经有所不同，我们可以想象这是一个多么复杂的问题。

上面这幅图引入了受保护特征的概念，在这些规定的受保护特征上面如果有歧视和不公平的发生就可能触犯法律。

## Reference
https://actuaries.asn.au/Library/Miscellaneous/2020/ADWGPaperFinal.pdf



