---
layout: post
comments: true
title: Algorithms Auditing：你的代码公平正义吗？
published: true
---


## 从王思聪微博抽奖说起

前几天，王思聪在微博上举办了一次抽奖活动，奖金是一万块。

>为庆祝iG夺冠，王思聪于2018年11月6日通过微博发布冠军之月庆祝抽奖活动。这次王思聪113人的中奖名单，有112人的性别为女性，男性只有1人。这里说的是微博资料的性别。另外苹果手机占这113人的78%，而苹果手机在中国市场的占有率不到10%。

网友这下炸开了锅。铁杆LOL粉全都抽不中，奖金都给了路人中产白领女。

![](/images/201811/wangsicong.jpeg)

身为一个技术宅，第一反应还是同情了一下同行。之前的百度竞价排名，搜索引擎排名要无痕加入竞价权重可能还是需要一些模型。马蜂窝爬取大众点评携程数据的造假事件，写过爬虫的人也都知道跟反爬虫的网站干起来是多么惨烈，虚拟点评更是有些创意了都。至于王思聪的抽奖，微博CEO解释是为了防止被机器号抽中，想必这背后也是各种训练调参。

可是这么多次事件出来，给人的感觉还是赢了技术，输了人格。

应该怪法律团队吗？好像也确实没违法。测试团队呢？所有按钮都点了一遍可能的流程都遍历过了是真没bug。模型团队呢？A/B testing也都通过了效果很不错呢。


## “古板守旧”的传统行业

自己进入保险行业做数据科学这近一年，最大的感触就是规管太多，手脚束缚。

保险的整条业务线其实很符合一家数据公司的商业模式：根据用户需求推销保险产品，用户投保，核保，定制保险产品内容，定价，售后服务，用户损失赔付，保单续约等等；每一个环节都可能产生数据，训练模型，定制化和自动化。

还等什么呢？Shut up and show me the AUC，撸起袖子干呗!

![](/images/201811/ml_fail.png)

现实是审计部门和法律部门的同事分分钟就坐在旁边虎视眈眈。每个月几封规管政策邮件，时不时发一封可爱的钓鱼邮件测试警惕性。你的数据哪来的，怎么存的，有敏感信息吗，能出境吗？你的模型怎么解释，为什么薇薇安-翠花的保费就是比约翰-狗蛋贵，有性别歧视和年龄歧视的风险吗？etc etc...

几轮之后就想摔键盘了。码农的莫名优越感不由得膨胀出来：你知道我们曾经一个调参帮老板赚了多少钱么，你知道我们曾经一个优雅模型帮老板多卖了几倍广告么，你知道我们曾经一个顺滑自动化系统帮老板少雇了多少低端劳动力么，你知道...

直到最近，看到一些新闻，我才认真问自己一些无关算法模型和准确度的问题。

也许我们缺的，是一个算法或者模型的审计功能：**Algorithms Auditor**？


## 算法审计 when and who？

什么时候需要算法审计，由谁来做算法审计呢。这个问题可以想得很远，我们大胆猜测也有可能会产生一整个相关产业链。

亚马逊推荐商品，Spotify推荐歌曲，乃至今日头条推荐新闻，这些可能只需要商家做**内部算法审计**，因为这些场景“不道德”的风险很低；模型表现差，顶多用户不喜欢不玩了，商家损失利润。未来大公司的数据科学团队可能会细化分工出这么一个内部算法审计团队，类似IT的测试团队。

至于“旅游独角兽”爬数据这件事，要去审计的大概是那些把估值捧上天的投资人们，这时候可能需要有一些**民间第三方算法审计公司**，可以是咨询公司的一个部门，也可以是创业公司。

而互联网抽奖平台，银行放贷评估，保险公司核保，可能也包括搜索引擎结果，这些传统上就应该接受非常严格政府规管的行业想要接入算法和模型，就需要几个**公信力十足的官方算法审计大佬**了。


## 算法审计 how?

算法怎么审计？这是核心问题也是技术上最有意思的部分。我的理解大体可以分为**结果统计审计，模型逻辑审计和特征权重审计**三种。

### Audit on Results

直接把算法产生的批量结果拿来审计可能是最直接简单的方法，一些最简单的数据挖掘和可视化已经能说明很多问题。网友发现王思聪抽奖结果全是女性和iPhone用户，就足以质疑抽奖的公平性。

![](/images/201811/wangsicong_statistics.jpg)

### Audit on Models

如果是一些规则系统，或是简单的线性模型，模型本身就可能可以直接用来审计了。规则系统不用多说，性别歧视年龄歧视的规则绝对扎眼。微博的去除机器号的系统假如是个线性模型，也大概可以直接计算出不同特征的权重，很容易发现安卓系统和男性的参数权重彻底主宰了判别机器号的模型。

对于非线性的黑箱模型，可解释性就成了一个关键问题。一个思路是如Hinton大神的[Distilling a Neural Network Into a Soft Decision Tree](https://arxiv.org/abs/1711.09784)，将神经网络等复杂模型近似为一个决策树模型的规则系统，从而理解模型的决策逻辑。

![](/images/201811/xiangqin.jpg)

### Audit on Features

对于黑箱模型，另一个方向是在预测时的特征权重上下功夫。当前已经有不少学术研究在从这个角度试图解释黑箱模型，如[LIME](https://github.com/marcotcr/lime)试图在一个局部区域内用线性模型拟合原先的黑箱模型计算特定预测结果的特征权重，或者[SHAP](https://github.com/slundberg/shap)使用shapley value将各种特征排列组合然后计算特征权重。

![](/images/201811/shap.png)


## 所以，你的代码公平正义吗？

随着机器学习模型越来越复杂和不透明，随着金融保险等强规管行业也在把目光投向人工智能，也随着中国互联网从业人员们越来越鸡贼，我们是该认真谈谈算法解释性、公平性和从业者职业道德的时候了。这不是改一改目标优化函数那么简单。

**算法审计，Algorithms Auditing**，可能是解决很多问题的关键。一方面规管了现有无底线的互联网玩法让我等在抢红包的时候心态平和一些，一方面也给金融保险等强规管行业一针使用人工智能的强心剂。

Is your code ethical and fair？反正王思聪的奖我是没抽中。如果你就是在微博做机器号僵尸粉识别的兄弟，欢迎开源代码然后艾特我下呢。